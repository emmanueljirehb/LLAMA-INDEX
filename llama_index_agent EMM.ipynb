{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dd2f6e3-1c0a-4f52-803a-956639b58eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index==0.12.43\n",
      "  Downloading llama_index-0.12.43-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting llama-index-agent-openai<0.5,>=0.4.0 (from llama-index==0.12.43)\n",
      "  Downloading llama_index_agent_openai-0.4.11-py3-none-any.whl.metadata (439 bytes)\n",
      "Collecting llama-index-cli<0.5,>=0.4.2 (from llama-index==0.12.43)\n",
      "  Downloading llama_index_cli-0.4.3-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting llama-index-core<0.13,>=0.12.43 (from llama-index==0.12.43)\n",
      "  Downloading llama_index_core-0.12.44-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting llama-index-embeddings-openai<0.4,>=0.3.0 (from llama-index==0.12.43)\n",
      "  Downloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl.metadata (684 bytes)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in d:\\ju\\lib\\site-packages (from llama-index==0.12.43) (0.6.0)\n",
      "Collecting llama-index-llms-openai<0.5,>=0.4.0 (from llama-index==0.12.43)\n",
      "  Downloading llama_index_llms_openai-0.4.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting llama-index-multi-modal-llms-openai<0.6,>=0.5.0 (from llama-index==0.12.43)\n",
      "  Downloading llama_index_multi_modal_llms_openai-0.5.1-py3-none-any.whl.metadata (440 bytes)\n",
      "Collecting llama-index-program-openai<0.4,>=0.3.0 (from llama-index==0.12.43)\n",
      "  Downloading llama_index_program_openai-0.3.2-py3-none-any.whl.metadata (473 bytes)\n",
      "Collecting llama-index-question-gen-openai<0.4,>=0.3.0 (from llama-index==0.12.43)\n",
      "  Downloading llama_index_question_gen_openai-0.3.1-py3-none-any.whl.metadata (492 bytes)\n",
      "Collecting llama-index-readers-file<0.5,>=0.4.0 (from llama-index==0.12.43)\n",
      "  Downloading llama_index_readers_file-0.4.9-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting llama-index-readers-llama-parse>=0.4.0 (from llama-index==0.12.43)\n",
      "  Using cached llama_index_readers_llama_parse-0.4.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: nltk>3.8.1 in d:\\ju\\lib\\site-packages (from llama-index==0.12.43) (3.9.1)\n",
      "Requirement already satisfied: openai>=1.14.0 in d:\\ju\\lib\\site-packages (from llama-index-agent-openai<0.5,>=0.4.0->llama-index==0.12.43) (1.91.0)\n",
      "Requirement already satisfied: aiohttp<4,>=3.8.6 in d:\\ju\\lib\\site-packages (from llama-index-core<0.13,>=0.12.43->llama-index==0.12.43) (3.10.5)\n",
      "Collecting aiosqlite (from llama-index-core<0.13,>=0.12.43->llama-index==0.12.43)\n",
      "  Downloading aiosqlite-0.21.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting banks<3,>=2.0.0 (from llama-index-core<0.13,>=0.12.43->llama-index==0.12.43)\n",
      "  Downloading banks-2.1.3-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: dataclasses-json in d:\\ju\\lib\\site-packages (from llama-index-core<0.13,>=0.12.43->llama-index==0.12.43) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in d:\\ju\\lib\\site-packages (from llama-index-core<0.13,>=0.12.43->llama-index==0.12.43) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2,>=1.0.8 in d:\\ju\\lib\\site-packages (from llama-index-core<0.13,>=0.12.43->llama-index==0.12.43) (1.0.8)\n",
      "Requirement already satisfied: filetype<2,>=1.2.0 in d:\\ju\\lib\\site-packages (from llama-index-core<0.13,>=0.12.43->llama-index==0.12.43) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\ju\\lib\\site-packages (from llama-index-core<0.13,>=0.12.43->llama-index==0.12.43) (2024.6.1)\n",
      "Requirement already satisfied: httpx in d:\\ju\\lib\\site-packages (from llama-index-core<0.13,>=0.12.43->llama-index==0.12.43) (0.27.0)\n",
      "Collecting llama-index-workflows<2,>=1.0.1 (from llama-index-core<0.13,>=0.12.43->llama-index==0.12.43)\n",
      "  Downloading llama_index_workflows-1.0.1-py3-none-any.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in d:\\ju\\lib\\site-packages (from llama-index-core<0.13,>=0.12.43->llama-index==0.12.43) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in d:\\ju\\lib\\site-packages (from llama-index-core<0.13,>=0.12.43->llama-index==0.12.43) (3.3)\n",
      "Requirement already satisfied: numpy in d:\\ju\\lib\\site-packages (from llama-index-core<0.13,>=0.12.43->llama-index==0.12.43) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in d:\\ju\\lib\\site-packages (from llama-index-core<0.13,>=0.12.43->llama-index==0.12.43) (10.4.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in d:\\ju\\lib\\site-packages (from llama-index-core<0.13,>=0.12.43->llama-index==0.12.43) (2.8.2)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in d:\\ju\\lib\\site-packages (from llama-index-core<0.13,>=0.12.43->llama-index==0.12.43) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.31.0 in d:\\ju\\lib\\site-packages (from llama-index-core<0.13,>=0.12.43->llama-index==0.12.43) (2.32.3)\n",
      "Collecting setuptools>=80.9.0 (from llama-index-core<0.13,>=0.12.43->llama-index==0.12.43)\n",
      "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.49 in d:\\ju\\lib\\site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.43->llama-index==0.12.43) (2.0.34)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in d:\\ju\\lib\\site-packages (from llama-index-core<0.13,>=0.12.43->llama-index==0.12.43) (8.2.3)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in d:\\ju\\lib\\site-packages (from llama-index-core<0.13,>=0.12.43->llama-index==0.12.43) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5,>=4.66.1 in d:\\ju\\lib\\site-packages (from llama-index-core<0.13,>=0.12.43->llama-index==0.12.43) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in d:\\ju\\lib\\site-packages (from llama-index-core<0.13,>=0.12.43->llama-index==0.12.43) (4.14.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in d:\\ju\\lib\\site-packages (from llama-index-core<0.13,>=0.12.43->llama-index==0.12.43) (0.9.0)\n",
      "Requirement already satisfied: wrapt in d:\\ju\\lib\\site-packages (from llama-index-core<0.13,>=0.12.43->llama-index==0.12.43) (1.14.1)\n",
      "Requirement already satisfied: llama-cloud>=0.1.5 in d:\\ju\\lib\\site-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index==0.12.43) (0.1.19)\n",
      "INFO: pip is looking at multiple versions of llama-index-indices-managed-llama-cloud to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting llama-index-indices-managed-llama-cloud>=0.4.0 (from llama-index==0.12.43)\n",
      "  Using cached llama_index_indices_managed_llama_cloud-0.7.7-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-cloud==0.1.26 (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index==0.12.43)\n",
      "  Using cached llama_cloud-0.1.26-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: certifi>=2024.7.4 in d:\\ju\\lib\\site-packages (from llama-cloud==0.1.26->llama-index-indices-managed-llama-cloud>=0.4.0->llama-index==0.12.43) (2024.8.30)\n",
      "Requirement already satisfied: beautifulsoup4<5,>=4.12.3 in d:\\ju\\lib\\site-packages (from llama-index-readers-file<0.5,>=0.4.0->llama-index==0.12.43) (4.12.3)\n",
      "Requirement already satisfied: pandas<2.3.0 in d:\\ju\\lib\\site-packages (from llama-index-readers-file<0.5,>=0.4.0->llama-index==0.12.43) (2.2.2)\n",
      "Collecting pypdf<6,>=5.1.0 (from llama-index-readers-file<0.5,>=0.4.0->llama-index==0.12.43)\n",
      "  Using cached pypdf-5.6.1-py3-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in d:\\ju\\lib\\site-packages (from llama-index-readers-file<0.5,>=0.4.0->llama-index==0.12.43) (0.0.26)\n",
      "Requirement already satisfied: llama-parse>=0.5.0 in d:\\ju\\lib\\site-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index==0.12.43) (0.6.21)\n",
      "Requirement already satisfied: click in d:\\ju\\lib\\site-packages (from nltk>3.8.1->llama-index==0.12.43) (8.1.7)\n",
      "Requirement already satisfied: joblib in d:\\ju\\lib\\site-packages (from nltk>3.8.1->llama-index==0.12.43) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\ju\\lib\\site-packages (from nltk>3.8.1->llama-index==0.12.43) (2024.9.11)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in d:\\ju\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.43->llama-index==0.12.43) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\ju\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.43->llama-index==0.12.43) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\ju\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.43->llama-index==0.12.43) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\ju\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.43->llama-index==0.12.43) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\ju\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.43->llama-index==0.12.43) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in d:\\ju\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.43->llama-index==0.12.43) (1.11.0)\n",
      "Collecting griffe (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.43->llama-index==0.12.43)\n",
      "  Downloading griffe-1.7.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: jinja2 in d:\\ju\\lib\\site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.43->llama-index==0.12.43) (3.1.4)\n",
      "Requirement already satisfied: platformdirs in d:\\ju\\lib\\site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.43->llama-index==0.12.43) (4.3.8)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\ju\\lib\\site-packages (from beautifulsoup4<5,>=4.12.3->llama-index-readers-file<0.5,>=0.4.0->llama-index==0.12.43) (2.5)\n",
      "Requirement already satisfied: anyio in d:\\ju\\lib\\site-packages (from httpx->llama-index-core<0.13,>=0.12.43->llama-index==0.12.43) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\ju\\lib\\site-packages (from httpx->llama-index-core<0.13,>=0.12.43->llama-index==0.12.43) (1.0.2)\n",
      "Requirement already satisfied: idna in d:\\ju\\lib\\site-packages (from httpx->llama-index-core<0.13,>=0.12.43->llama-index==0.12.43) (3.7)\n",
      "Requirement already satisfied: sniffio in d:\\ju\\lib\\site-packages (from httpx->llama-index-core<0.13,>=0.12.43->llama-index==0.12.43) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\ju\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.13,>=0.12.43->llama-index==0.12.43) (0.14.0)\n",
      "Collecting llama-index-instrumentation>=0.1.0 (from llama-index-workflows<2,>=1.0.1->llama-index-core<0.13,>=0.12.43->llama-index==0.12.43)\n",
      "  Downloading llama_index_instrumentation-0.2.0-py3-none-any.whl.metadata (252 bytes)\n",
      "Collecting pydantic>=2.8.0 (from llama-index-core<0.13,>=0.12.43->llama-index==0.12.43)\n",
      "  Downloading pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Requirement already satisfied: llama-cloud-services>=0.6.21 in d:\\ju\\lib\\site-packages (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index==0.12.43) (0.6.21)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\ju\\lib\\site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index==0.12.43) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in d:\\ju\\lib\\site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index==0.12.43) (0.9.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\ju\\lib\\site-packages (from pandas<2.3.0->llama-index-readers-file<0.5,>=0.4.0->llama-index==0.12.43) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\ju\\lib\\site-packages (from pandas<2.3.0->llama-index-readers-file<0.5,>=0.4.0->llama-index==0.12.43) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\ju\\lib\\site-packages (from pandas<2.3.0->llama-index-readers-file<0.5,>=0.4.0->llama-index==0.12.43) (2023.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\ju\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.43->llama-index==0.12.43) (0.6.0)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.43->llama-index==0.12.43)\n",
      "  Downloading pydantic_core-2.33.2-cp312-cp312-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in d:\\ju\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.43->llama-index==0.12.43) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\ju\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.43->llama-index==0.12.43) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\ju\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.43->llama-index==0.12.43) (2.2.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in d:\\ju\\lib\\site-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.43->llama-index==0.12.43) (3.0.1)\n",
      "Requirement already satisfied: colorama in d:\\ju\\lib\\site-packages (from tqdm<5,>=4.66.1->llama-index-core<0.13,>=0.12.43->llama-index==0.12.43) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in d:\\ju\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13,>=0.12.43->llama-index==0.12.43) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in d:\\ju\\lib\\site-packages (from dataclasses-json->llama-index-core<0.13,>=0.12.43->llama-index==0.12.43) (3.26.1)\n",
      "INFO: pip is looking at multiple versions of llama-cloud-services to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting llama-cloud-services>=0.6.21 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index==0.12.43)\n",
      "  Downloading llama_cloud_services-0.6.39-py3-none-any.whl.metadata (3.5 kB)\n",
      "  Downloading llama_cloud_services-0.6.38-py3-none-any.whl.metadata (3.5 kB)\n",
      "  Using cached llama_cloud_services-0.6.37-py3-none-any.whl.metadata (3.5 kB)\n",
      "  Using cached llama_cloud_services-0.6.36-py3-none-any.whl.metadata (3.5 kB)\n",
      "  Using cached llama_cloud_services-0.6.35-py3-none-any.whl.metadata (3.4 kB)\n",
      "  Using cached llama_cloud_services-0.6.34-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in d:\\ju\\lib\\site-packages (from llama-cloud-services>=0.6.21->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index==0.12.43) (1.1.1)\n",
      "Requirement already satisfied: packaging>=17.0 in d:\\ju\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13,>=0.12.43->llama-index==0.12.43) (24.1)\n",
      "Requirement already satisfied: six>=1.5 in d:\\ju\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<2.3.0->llama-index-readers-file<0.5,>=0.4.0->llama-index==0.12.43) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\ju\\lib\\site-packages (from jinja2->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.43->llama-index==0.12.43) (2.1.3)\n",
      "Downloading llama_index-0.12.43-py3-none-any.whl (7.1 kB)\n",
      "Downloading llama_index_agent_openai-0.4.11-py3-none-any.whl (14 kB)\n",
      "Downloading llama_index_cli-0.4.3-py3-none-any.whl (28 kB)\n",
      "Downloading llama_index_core-0.12.44-py3-none-any.whl (7.6 MB)\n",
      "   ---------------------------------------- 0.0/7.6 MB ? eta -:--:--\n",
      "   ------------------------ --------------- 4.7/7.6 MB 23.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.6/7.6 MB 22.5 MB/s eta 0:00:00\n",
      "Downloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl (6.2 kB)\n",
      "Downloading llama_index_indices_managed_llama_cloud-0.7.7-py3-none-any.whl (16 kB)\n",
      "Downloading llama_cloud-0.1.26-py3-none-any.whl (266 kB)\n",
      "Downloading llama_index_llms_openai-0.4.7-py3-none-any.whl (25 kB)\n",
      "Downloading llama_index_multi_modal_llms_openai-0.5.1-py3-none-any.whl (3.4 kB)\n",
      "Downloading llama_index_program_openai-0.3.2-py3-none-any.whl (6.1 kB)\n",
      "Downloading llama_index_question_gen_openai-0.3.1-py3-none-any.whl (3.7 kB)\n",
      "Downloading llama_index_readers_file-0.4.9-py3-none-any.whl (40 kB)\n",
      "Downloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl (2.5 kB)\n",
      "Downloading banks-2.1.3-py3-none-any.whl (28 kB)\n",
      "Downloading llama_index_workflows-1.0.1-py3-none-any.whl (36 kB)\n",
      "Downloading pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.0/2.0 MB 18.0 MB/s eta 0:00:00\n",
      "Using cached pypdf-5.6.1-py3-none-any.whl (304 kB)\n",
      "Using cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "Downloading aiosqlite-0.21.0-py3-none-any.whl (15 kB)\n",
      "Downloading llama_cloud_services-0.6.34-py3-none-any.whl (39 kB)\n",
      "Downloading llama_index_instrumentation-0.2.0-py3-none-any.whl (14 kB)\n",
      "Downloading griffe-1.7.3-py3-none-any.whl (129 kB)\n",
      "Installing collected packages: setuptools, pypdf, pydantic-core, griffe, aiosqlite, pydantic, llama-index-instrumentation, llama-cloud, banks, llama-index-workflows, llama-index-core, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-cloud-services, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-readers-llama-parse, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 75.1.0\n",
      "    Uninstalling setuptools-75.1.0:\n",
      "      Successfully uninstalled setuptools-75.1.0\n",
      "  Attempting uninstall: pypdf\n",
      "    Found existing installation: pypdf 4.3.1\n",
      "    Uninstalling pypdf-4.3.1:\n",
      "      Successfully uninstalled pypdf-4.3.1\n",
      "  Attempting uninstall: pydantic-core\n",
      "    Found existing installation: pydantic_core 2.20.1\n",
      "    Uninstalling pydantic_core-2.20.1:\n",
      "      Successfully uninstalled pydantic_core-2.20.1\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.8.2\n",
      "    Uninstalling pydantic-2.8.2:\n",
      "      Successfully uninstalled pydantic-2.8.2\n",
      "  Attempting uninstall: llama-cloud\n",
      "    Found existing installation: llama-cloud 0.1.19\n",
      "    Uninstalling llama-cloud-0.1.19:\n",
      "      Successfully uninstalled llama-cloud-0.1.19\n",
      "  Attempting uninstall: llama-index-core\n",
      "    Found existing installation: llama-index-core 0.11.23\n",
      "    Uninstalling llama-index-core-0.11.23:\n",
      "      Successfully uninstalled llama-index-core-0.11.23\n",
      "  Attempting uninstall: llama-index-readers-file\n",
      "    Found existing installation: llama-index-readers-file 0.2.2\n",
      "    Uninstalling llama-index-readers-file-0.2.2:\n",
      "      Successfully uninstalled llama-index-readers-file-0.2.2\n",
      "  Attempting uninstall: llama-index-llms-openai\n",
      "    Found existing installation: llama-index-llms-openai 0.2.16\n",
      "    Uninstalling llama-index-llms-openai-0.2.16:\n",
      "      Successfully uninstalled llama-index-llms-openai-0.2.16\n",
      "  Attempting uninstall: llama-index-indices-managed-llama-cloud\n",
      "    Found existing installation: llama-index-indices-managed-llama-cloud 0.6.0\n",
      "    Uninstalling llama-index-indices-managed-llama-cloud-0.6.0:\n",
      "      Successfully uninstalled llama-index-indices-managed-llama-cloud-0.6.0\n",
      "  Attempting uninstall: llama-index-embeddings-openai\n",
      "    Found existing installation: llama-index-embeddings-openai 0.2.5\n",
      "    Uninstalling llama-index-embeddings-openai-0.2.5:\n",
      "      Successfully uninstalled llama-index-embeddings-openai-0.2.5\n",
      "  Attempting uninstall: llama-cloud-services\n",
      "    Found existing installation: llama-cloud-services 0.6.21\n",
      "    Uninstalling llama-cloud-services-0.6.21:\n",
      "      Successfully uninstalled llama-cloud-services-0.6.21\n",
      "  Attempting uninstall: llama-index-multi-modal-llms-openai\n",
      "    Found existing installation: llama-index-multi-modal-llms-openai 0.2.3\n",
      "    Uninstalling llama-index-multi-modal-llms-openai-0.2.3:\n",
      "      Successfully uninstalled llama-index-multi-modal-llms-openai-0.2.3\n",
      "  Attempting uninstall: llama-index-cli\n",
      "    Found existing installation: llama-index-cli 0.3.1\n",
      "    Uninstalling llama-index-cli-0.3.1:\n",
      "      Successfully uninstalled llama-index-cli-0.3.1\n",
      "  Attempting uninstall: llama-index-agent-openai\n",
      "    Found existing installation: llama-index-agent-openai 0.3.4\n",
      "    Uninstalling llama-index-agent-openai-0.3.4:\n",
      "      Successfully uninstalled llama-index-agent-openai-0.3.4\n",
      "  Attempting uninstall: llama-index-readers-llama-parse\n",
      "    Found existing installation: llama-index-readers-llama-parse 0.3.0\n",
      "    Uninstalling llama-index-readers-llama-parse-0.3.0:\n",
      "      Successfully uninstalled llama-index-readers-llama-parse-0.3.0\n",
      "  Attempting uninstall: llama-index-program-openai\n",
      "    Found existing installation: llama-index-program-openai 0.2.0\n",
      "    Uninstalling llama-index-program-openai-0.2.0:\n",
      "      Successfully uninstalled llama-index-program-openai-0.2.0\n",
      "  Attempting uninstall: llama-index-question-gen-openai\n",
      "    Found existing installation: llama-index-question-gen-openai 0.2.0\n",
      "    Uninstalling llama-index-question-gen-openai-0.2.0:\n",
      "      Successfully uninstalled llama-index-question-gen-openai-0.2.0\n",
      "  Attempting uninstall: llama-index\n",
      "    Found existing installation: llama-index 0.11.9\n",
      "    Uninstalling llama-index-0.11.9:\n",
      "      Successfully uninstalled llama-index-0.11.9\n",
      "Successfully installed aiosqlite-0.21.0 banks-2.1.3 griffe-1.7.3 llama-cloud-0.1.26 llama-cloud-services-0.6.34 llama-index-0.12.43 llama-index-agent-openai-0.4.11 llama-index-cli-0.4.3 llama-index-core-0.12.44 llama-index-embeddings-openai-0.3.1 llama-index-indices-managed-llama-cloud-0.7.7 llama-index-instrumentation-0.2.0 llama-index-llms-openai-0.4.7 llama-index-multi-modal-llms-openai-0.5.1 llama-index-program-openai-0.3.2 llama-index-question-gen-openai-0.3.1 llama-index-readers-file-0.4.9 llama-index-readers-llama-parse-0.4.0 llama-index-workflows-1.0.1 pydantic-2.11.7 pydantic-core-2.33.2 pypdf-5.6.1 setuptools-80.9.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'D:\\ju\\Lib\\site-packages\\~ydantic_core'.\n",
      "  You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade llama-index==0.12.43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fe568c6-1ed1-46a0-a868-8abf5b743051",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ[\"OPENAI_API_KEY\"]=\"\"\n",
    "os.environ[\"OPENAI_API_KEY\"]=\"insert your api key here \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3431e458-4fbf-499e-9478-e0f74e3c00b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-********************************************************************************************************************************************************NbcA. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m reader\u001b[38;5;241m=\u001b[39mSimpleDirectoryReader(input_files\u001b[38;5;241m=\u001b[39m[f_path])\n\u001b[0;32m     10\u001b[0m pdf_documents \u001b[38;5;241m=\u001b[39m reader\u001b[38;5;241m.\u001b[39mload_data()\n\u001b[1;32m---> 11\u001b[0m index \u001b[38;5;241m=\u001b[39m VectorStoreIndex\u001b[38;5;241m.\u001b[39mfrom_documents(pdf_documents)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Step 2: Create a query engine\u001b[39;00m\n\u001b[0;32m     14\u001b[0m query_engine \u001b[38;5;241m=\u001b[39m index\u001b[38;5;241m.\u001b[39mas_query_engine()\n",
      "File \u001b[1;32mD:\\ju\\Lib\\site-packages\\llama_index\\core\\indices\\base.py:122\u001b[0m, in \u001b[0;36mBaseIndex.from_documents\u001b[1;34m(cls, documents, storage_context, show_progress, callback_manager, transformations, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m     docstore\u001b[38;5;241m.\u001b[39mset_document_hash(doc\u001b[38;5;241m.\u001b[39mget_doc_id(), doc\u001b[38;5;241m.\u001b[39mhash)\n\u001b[0;32m    115\u001b[0m nodes \u001b[38;5;241m=\u001b[39m run_transformations(\n\u001b[0;32m    116\u001b[0m     documents,  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    117\u001b[0m     transformations,\n\u001b[0;32m    118\u001b[0m     show_progress\u001b[38;5;241m=\u001b[39mshow_progress,\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    120\u001b[0m )\n\u001b[1;32m--> 122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\n\u001b[0;32m    123\u001b[0m     nodes\u001b[38;5;241m=\u001b[39mnodes,\n\u001b[0;32m    124\u001b[0m     storage_context\u001b[38;5;241m=\u001b[39mstorage_context,\n\u001b[0;32m    125\u001b[0m     callback_manager\u001b[38;5;241m=\u001b[39mcallback_manager,\n\u001b[0;32m    126\u001b[0m     show_progress\u001b[38;5;241m=\u001b[39mshow_progress,\n\u001b[0;32m    127\u001b[0m     transformations\u001b[38;5;241m=\u001b[39mtransformations,\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    129\u001b[0m )\n",
      "File \u001b[1;32mD:\\ju\\Lib\\site-packages\\llama_index\\core\\indices\\vector_store\\base.py:77\u001b[0m, in \u001b[0;36mVectorStoreIndex.__init__\u001b[1;34m(self, nodes, use_async, store_nodes_override, embed_model, insert_batch_size, objects, index_struct, storage_context, callback_manager, transformations, show_progress, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embed_model \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     71\u001b[0m     resolve_embed_model(embed_model, callback_manager\u001b[38;5;241m=\u001b[39mcallback_manager)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m embed_model\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m Settings\u001b[38;5;241m.\u001b[39membed_model\n\u001b[0;32m     74\u001b[0m )\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insert_batch_size \u001b[38;5;241m=\u001b[39m insert_batch_size\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     78\u001b[0m     nodes\u001b[38;5;241m=\u001b[39mnodes,\n\u001b[0;32m     79\u001b[0m     index_struct\u001b[38;5;241m=\u001b[39mindex_struct,\n\u001b[0;32m     80\u001b[0m     storage_context\u001b[38;5;241m=\u001b[39mstorage_context,\n\u001b[0;32m     81\u001b[0m     show_progress\u001b[38;5;241m=\u001b[39mshow_progress,\n\u001b[0;32m     82\u001b[0m     objects\u001b[38;5;241m=\u001b[39mobjects,\n\u001b[0;32m     83\u001b[0m     callback_manager\u001b[38;5;241m=\u001b[39mcallback_manager,\n\u001b[0;32m     84\u001b[0m     transformations\u001b[38;5;241m=\u001b[39mtransformations,\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m     86\u001b[0m )\n",
      "File \u001b[1;32mD:\\ju\\Lib\\site-packages\\llama_index\\core\\indices\\base.py:79\u001b[0m, in \u001b[0;36mBaseIndex.__init__\u001b[1;34m(self, nodes, objects, index_struct, storage_context, callback_manager, transformations, show_progress, **kwargs)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index_struct \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m     nodes \u001b[38;5;241m=\u001b[39m nodes \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[1;32m---> 79\u001b[0m     index_struct \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_index_from_nodes(\n\u001b[0;32m     80\u001b[0m         nodes \u001b[38;5;241m+\u001b[39m objects,  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m     81\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m     82\u001b[0m     )\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_struct \u001b[38;5;241m=\u001b[39m index_struct\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_storage_context\u001b[38;5;241m.\u001b[39mindex_store\u001b[38;5;241m.\u001b[39madd_index_struct(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_struct)\n",
      "File \u001b[1;32mD:\\ju\\Lib\\site-packages\\llama_index\\core\\indices\\vector_store\\base.py:311\u001b[0m, in \u001b[0;36mVectorStoreIndex.build_index_from_nodes\u001b[1;34m(self, nodes, **insert_kwargs)\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(content_nodes) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(nodes):\n\u001b[0;32m    309\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSome nodes are missing content, skipping them...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_index_from_nodes(content_nodes, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minsert_kwargs)\n",
      "File \u001b[1;32mD:\\ju\\Lib\\site-packages\\llama_index\\core\\indices\\vector_store\\base.py:280\u001b[0m, in \u001b[0;36mVectorStoreIndex._build_index_from_nodes\u001b[1;34m(self, nodes, **insert_kwargs)\u001b[0m\n\u001b[0;32m    278\u001b[0m     run_async_tasks(tasks)\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 280\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_nodes_to_index(\n\u001b[0;32m    281\u001b[0m         index_struct,\n\u001b[0;32m    282\u001b[0m         nodes,\n\u001b[0;32m    283\u001b[0m         show_progress\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_show_progress,\n\u001b[0;32m    284\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minsert_kwargs,\n\u001b[0;32m    285\u001b[0m     )\n\u001b[0;32m    286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m index_struct\n",
      "File \u001b[1;32mD:\\ju\\Lib\\site-packages\\llama_index\\core\\indices\\vector_store\\base.py:233\u001b[0m, in \u001b[0;36mVectorStoreIndex._add_nodes_to_index\u001b[1;34m(self, index_struct, nodes, show_progress, **insert_kwargs)\u001b[0m\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m nodes_batch \u001b[38;5;129;01min\u001b[39;00m iter_batch(nodes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insert_batch_size):\n\u001b[1;32m--> 233\u001b[0m     nodes_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_node_with_embedding(nodes_batch, show_progress)\n\u001b[0;32m    234\u001b[0m     new_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_vector_store\u001b[38;5;241m.\u001b[39madd(nodes_batch, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minsert_kwargs)\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_vector_store\u001b[38;5;241m.\u001b[39mstores_text \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_store_nodes_override:\n\u001b[0;32m    237\u001b[0m         \u001b[38;5;66;03m# NOTE: if the vector store doesn't store text,\u001b[39;00m\n\u001b[0;32m    238\u001b[0m         \u001b[38;5;66;03m# we need to add the nodes to the index struct and document store\u001b[39;00m\n",
      "File \u001b[1;32mD:\\ju\\Lib\\site-packages\\llama_index\\core\\indices\\vector_store\\base.py:140\u001b[0m, in \u001b[0;36mVectorStoreIndex._get_node_with_embedding\u001b[1;34m(self, nodes, show_progress)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_node_with_embedding\u001b[39m(\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    130\u001b[0m     nodes: Sequence[BaseNode],\n\u001b[0;32m    131\u001b[0m     show_progress: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    132\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[BaseNode]:\n\u001b[0;32m    133\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;124;03m    Get tuples of id, node, and embedding.\u001b[39;00m\n\u001b[0;32m    135\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    138\u001b[0m \n\u001b[0;32m    139\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 140\u001b[0m     id_to_embed_map \u001b[38;5;241m=\u001b[39m embed_nodes(\n\u001b[0;32m    141\u001b[0m         nodes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embed_model, show_progress\u001b[38;5;241m=\u001b[39mshow_progress\n\u001b[0;32m    142\u001b[0m     )\n\u001b[0;32m    144\u001b[0m     results \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m nodes:\n",
      "File \u001b[1;32mD:\\ju\\Lib\\site-packages\\llama_index\\core\\indices\\utils.py:165\u001b[0m, in \u001b[0;36membed_nodes\u001b[1;34m(nodes, embed_model, show_progress)\u001b[0m\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    163\u001b[0m         id_to_embed_map[node\u001b[38;5;241m.\u001b[39mnode_id] \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39membedding\n\u001b[1;32m--> 165\u001b[0m new_embeddings \u001b[38;5;241m=\u001b[39m embed_model\u001b[38;5;241m.\u001b[39mget_text_embedding_batch(\n\u001b[0;32m    166\u001b[0m     texts_to_embed, show_progress\u001b[38;5;241m=\u001b[39mshow_progress\n\u001b[0;32m    167\u001b[0m )\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m new_id, text_embedding \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(ids_to_embed, new_embeddings):\n\u001b[0;32m    170\u001b[0m     id_to_embed_map[new_id] \u001b[38;5;241m=\u001b[39m text_embedding\n",
      "File \u001b[1;32mD:\\ju\\Lib\\site-packages\\llama_index_instrumentation\\dispatcher.py:319\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    316\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 319\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[0;32m    322\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[1;32mD:\\ju\\Lib\\site-packages\\llama_index\\core\\base\\embeddings\\base.py:406\u001b[0m, in \u001b[0;36mBaseEmbedding.get_text_embedding_batch\u001b[1;34m(self, texts, show_progress, **kwargs)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mevent(\n\u001b[0;32m    402\u001b[0m     CBEventType\u001b[38;5;241m.\u001b[39mEMBEDDING,\n\u001b[0;32m    403\u001b[0m     payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mSERIALIZED: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_dict()},\n\u001b[0;32m    404\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m event:\n\u001b[0;32m    405\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings_cache:\n\u001b[1;32m--> 406\u001b[0m         embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_text_embeddings(cur_batch)\n\u001b[0;32m    407\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    408\u001b[0m         embeddings \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mD:\\ju\\Lib\\site-packages\\llama_index\\embeddings\\openai\\base.py:465\u001b[0m, in \u001b[0;36mOpenAIEmbedding._get_text_embeddings\u001b[1;34m(self, texts)\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_retryable_get_embeddings\u001b[39m():\n\u001b[0;32m    458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get_embeddings(\n\u001b[0;32m    459\u001b[0m         client,\n\u001b[0;32m    460\u001b[0m         texts,\n\u001b[0;32m    461\u001b[0m         engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_text_engine,\n\u001b[0;32m    462\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madditional_kwargs,\n\u001b[0;32m    463\u001b[0m     )\n\u001b[1;32m--> 465\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _retryable_get_embeddings()\n",
      "File \u001b[1;32mD:\\ju\\Lib\\site-packages\\tenacity\\__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_f\u001b[39m(\u001b[38;5;241m*\u001b[39margs: t\u001b[38;5;241m.\u001b[39mAny, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: t\u001b[38;5;241m.\u001b[39mAny) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mAny:\n\u001b[1;32m--> 289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(f, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32mD:\\ju\\Lib\\site-packages\\tenacity\\__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    377\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 379\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter(retry_state\u001b[38;5;241m=\u001b[39mretry_state)\n\u001b[0;32m    380\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    381\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\ju\\Lib\\site-packages\\tenacity\\__init__.py:314\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[1;34m(self, retry_state)\u001b[0m\n\u001b[0;32m    312\u001b[0m is_explicit_retry \u001b[38;5;241m=\u001b[39m fut\u001b[38;5;241m.\u001b[39mfailed \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fut\u001b[38;5;241m.\u001b[39mexception(), TryAgain)\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (is_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry(retry_state)):\n\u001b[1;32m--> 314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fut\u001b[38;5;241m.\u001b[39mresult()\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter(retry_state)\n",
      "File \u001b[1;32mD:\\ju\\Lib\\concurrent\\futures\\_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mD:\\ju\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mD:\\ju\\Lib\\site-packages\\tenacity\\__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    381\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 382\u001b[0m         result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    383\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[0;32m    384\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mD:\\ju\\Lib\\site-packages\\llama_index\\embeddings\\openai\\base.py:458\u001b[0m, in \u001b[0;36mOpenAIEmbedding._get_text_embeddings.<locals>._retryable_get_embeddings\u001b[1;34m()\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_retryable_get_embeddings\u001b[39m():\n\u001b[1;32m--> 458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get_embeddings(\n\u001b[0;32m    459\u001b[0m         client,\n\u001b[0;32m    460\u001b[0m         texts,\n\u001b[0;32m    461\u001b[0m         engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_text_engine,\n\u001b[0;32m    462\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madditional_kwargs,\n\u001b[0;32m    463\u001b[0m     )\n",
      "File \u001b[1;32mD:\\ju\\Lib\\site-packages\\llama_index\\embeddings\\openai\\base.py:169\u001b[0m, in \u001b[0;36mget_embeddings\u001b[1;34m(client, list_of_text, engine, **kwargs)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(list_of_text) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2048\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe batch size should not be larger than 2048.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    167\u001b[0m list_of_text \u001b[38;5;241m=\u001b[39m [text\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m list_of_text]\n\u001b[1;32m--> 169\u001b[0m data \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39membeddings\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mlist_of_text, model\u001b[38;5;241m=\u001b[39mengine, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\u001b[38;5;241m.\u001b[39mdata\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [d\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m data]\n",
      "File \u001b[1;32mD:\\ju\\Lib\\site-packages\\openai\\resources\\embeddings.py:129\u001b[0m, in \u001b[0;36mEmbeddings.create\u001b[1;34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    123\u001b[0m             embedding\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfrombuffer(  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[0;32m    124\u001b[0m                 base64\u001b[38;5;241m.\u001b[39mb64decode(data), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    125\u001b[0m             )\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[1;32m--> 129\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    131\u001b[0m     body\u001b[38;5;241m=\u001b[39mmaybe_transform(params, embedding_create_params\u001b[38;5;241m.\u001b[39mEmbeddingCreateParams),\n\u001b[0;32m    132\u001b[0m     options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[0;32m    133\u001b[0m         extra_headers\u001b[38;5;241m=\u001b[39mextra_headers,\n\u001b[0;32m    134\u001b[0m         extra_query\u001b[38;5;241m=\u001b[39mextra_query,\n\u001b[0;32m    135\u001b[0m         extra_body\u001b[38;5;241m=\u001b[39mextra_body,\n\u001b[0;32m    136\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    137\u001b[0m         post_parser\u001b[38;5;241m=\u001b[39mparser,\n\u001b[0;32m    138\u001b[0m     ),\n\u001b[0;32m    139\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mCreateEmbeddingResponse,\n\u001b[0;32m    140\u001b[0m )\n",
      "File \u001b[1;32mD:\\ju\\Lib\\site-packages\\openai\\_base_client.py:1249\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1235\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1236\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1237\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1244\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1245\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1246\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1247\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1248\u001b[0m     )\n\u001b[1;32m-> 1249\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls))\n",
      "File \u001b[1;32mD:\\ju\\Lib\\site-packages\\openai\\_base_client.py:1037\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1034\u001b[0m             err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1036\u001b[0m         log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1037\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcould not resolve response (should never happen)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mAuthenticationError\u001b[0m: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-********************************************************************************************************************************************************NbcA. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}"
     ]
    }
   ],
   "source": [
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex\n",
    "from llama_index.core.tools import QueryEngineTool\n",
    "from llama_index.agent.openai import OpenAIAgent\n",
    "\n",
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex\n",
    "\n",
    "f_path=\"D:/RAMANASOFT/alice-in-wonderland.pdf\"\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "reader=SimpleDirectoryReader(input_files=[f_path])\n",
    "pdf_documents = reader.load_data()\n",
    "index = VectorStoreIndex.from_documents(pdf_documents)\n",
    "\n",
    "# Step 2: Create a query engine\n",
    "query_engine = index.as_query_engine()\n",
    "\n",
    "# Step 3: Wrap query engine as a Tool\n",
    "tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=query_engine,\n",
    "    name=\"DocQA\",\n",
    "    description=\"Use this tool to answer questions based on the documents.\"\n",
    ")\n",
    "\n",
    "# Step 4: Create the agent with the tool\n",
    "agent = OpenAIAgent.from_tools(\n",
    "    tools=[tool],\n",
    "    system_prompt=\"You are a helpful assistant that answers questions using tools.\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Step 5: Chat with the agent\n",
    "response = agent.chat(\"Give me a summary of the documents.\")\n",
    "print(response.response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbf5c08-22b5-441c-8c31-2eee93bdd87e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
